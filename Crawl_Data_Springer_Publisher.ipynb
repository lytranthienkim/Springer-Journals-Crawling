{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from requests.adapters import HTTPAdapter, Retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://link.springer.com/journals/a/1'\n",
    "response = requests.get(url)\n",
    "soup = bs4.BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = 'https://link.springer.com'\n",
    "base_links_list = soup.find('ol', {'class', 'c-atoz-navigation u-mb-24'})\n",
    "get_link = [link['href'] for link in base_links_list.select('a')]\n",
    "journal_link_list = [urljoin(str(main_url), str(get_link)) for get_link in get_link]\n",
    "journal_link_list.insert(0, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = 'https://link.springer.com'\n",
    "base_links_list = soup.find('ol', {'class', 'c-atoz-navigation u-mb-24'})\n",
    "get_link = [link['href'] for link in base_links_list.select('a')]\n",
    "journal_link_list = [urljoin(str(main_url), str(get_link)) for get_link in get_link]\n",
    "journal_link_list.insert(0, url)\n",
    "\n",
    "list_source_page = []\n",
    "for i in range(len(journal_link_list)):\n",
    "    request = requests.get(journal_link_list[i])\n",
    "    soup = bs4.BeautifulSoup(request.content, 'html.parser')\n",
    "    source_link_page = soup.find_all('ol', {'class', 'c-pagination-listed__list'})\n",
    "    \n",
    "    for link in soup.find_all('a', {'class', 'c-pagination-listed__link'}):\n",
    "        journal = link.get('href')\n",
    "        list_source_page.append(journal)\n",
    "\n",
    "journal_link_extend_link = []     \n",
    "for j in range(len(list_source_page)):\n",
    "    rename_url = main_url + list_source_page[j]\n",
    "    journal_link_extend_link.append(rename_url)\n",
    "\n",
    "def combine_link_journal(journal_link_list, journal_link_extend_link):\n",
    "    journal_link_list += journal_link_extend_link\n",
    "    journal_link_list.sort()\n",
    "\n",
    "    rerange_link = journal_link_list.pop(0)\n",
    "    journal_link_list.append(rerange_link)\n",
    "\n",
    "    return journal_link_list\n",
    "\n",
    "result_list = combine_link_journal(journal_link_list, journal_link_extend_link)\n",
    "all_link_journals = list(dict.fromkeys(result_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_data = []\n",
    "STT = 0\n",
    "for link in range(len(all_link_journals)):\n",
    "    request = requests.get(all_link_journals[link])\n",
    "    soup = BeautifulSoup(request.content, 'html.parser')\n",
    "    title_category = soup.find('h1', class_='u-serif').text.strip()\n",
    "    name_category = soup.find_all('a', class_='c-atoz-list__link')\n",
    "\n",
    "    if not soup.find('a', class_='c-atoz-list__link'):\n",
    "        STT+=1\n",
    "        journal_data.append({\n",
    "                            'STT': STT,\n",
    "                            'Danh mục': title_category,\n",
    "                            'URL danh mục': all_link_journals[link],\n",
    "                            'Tên tạp chí': '0 có tạp chí'})\n",
    "\n",
    "    for name_text in name_category:\n",
    "        STT+=1\n",
    "        journal_data.append({                            \n",
    "                            'STT': STT,\n",
    "                            'Danh mục': title_category,\n",
    "                            'URL danh mục': all_link_journals[link],\n",
    "                            'Tên tạp chí': name_text.get_text().strip()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "springer_journals = pd.DataFrame(journal_data, columns = ['STT', 'Danh mục', 'URL danh mục', 'Tên tạp chí'])\n",
    "springer_journals.to_csv('Crawling Catalougue Springer Link Journals A-Z.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "\n",
    "adapter = HTTPAdapter(max_retries=Retry(total = 5, backoff_factor = 1, allowed_methods = None, status_forcelist=[429, 500, 502, 503, 504]))\n",
    "\n",
    "session.mount(\"http://\", adapter)\n",
    "session.mount(\"https://\", adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "springer_journals_data = []\n",
    "STT = 0\n",
    "for link in all_link_journals:\n",
    "    request = session.get(link, timeout=(5, 15))\n",
    "    soup = BeautifulSoup(request.content, 'html.parser')\n",
    "    href_values = [href_publications.get('href') for href_publications in soup.find_all('a', {'class': 'c-atoz-list__link'})]\n",
    "    name_categories = soup.find_all('a', class_='c-atoz-list__link')\n",
    "\n",
    "    for name_category, element in zip(name_categories, href_values):\n",
    "        try:\n",
    "            request = session.get(element)\n",
    "            soup = BeautifulSoup(request.content, 'html.parser')\n",
    "\n",
    "            #issn\n",
    "            print_issn_extract = None\n",
    "\n",
    "            print_issn_dt = soup.find('dt', class_='c-list-description__term', string = 'Print ISSN')\n",
    "            if print_issn_dt:\n",
    "                print_issn_extract = print_issn_dt.find_next('dd', class_='c-list-description__details').get_text(strip=True)\n",
    "\n",
    "            if print_issn_extract is None:\n",
    "                print_issn_online = soup.find('span', {'itemprop': 'onlineIssn'})\n",
    "                if print_issn_online:\n",
    "                    print_issn_extract = print_issn_online.get_text(strip=True)\n",
    "\n",
    "            if print_issn_extract is None:\n",
    "                print_issn_li = soup.find_all('li', {'style': 'list-style: none; margin-left: 0'})\n",
    "                for print_issn in print_issn_li:\n",
    "                    print_issn_extract = re.search(r'ISSN:\\s+(\\d{4}-\\d{4}) \\(print\\)', print_issn.get_text(strip=True))\n",
    "                    if print_issn_extract:\n",
    "                        print_issn_extract = print_issn_extract.group(1)\n",
    "                        break\n",
    "                    else:\n",
    "                        print_issn_extract = \" \"\n",
    "            \n",
    "            if print_issn_extract is None:\n",
    "                print_issn_footer = soup.find('p', {'class': 'c-journal-footer__issn'})\n",
    "                if print_issn_footer:\n",
    "                    print_issn_extract = re.search(r'\\s+(\\d{4}-\\d{4})', print_issn_footer.get_text(strip=True))\n",
    "                    if print_issn_extract:\n",
    "                        print_issn_extract = print_issn_extract.group(1)\n",
    "                    else:\n",
    "                        print_issn_extract = \" \"\n",
    "                else:\n",
    "                    print_issn_extract = \" \"\n",
    "\n",
    "            #electronic issn\n",
    "            electronic_issn_extract = None\n",
    "            \n",
    "            electronic_issn_dd = soup.find('dd', class_='c-list-description__details u-ma-0')\n",
    "            if electronic_issn_dd:\n",
    "                electronic_issn_extract = electronic_issn_dd.get_text(strip=True)\n",
    "\n",
    "            if electronic_issn_extract is None:\n",
    "                electronic_issn_li_elements = soup.find_all('li', {'style': 'list-style: none; margin-left: 0'})\n",
    "                for electronic_issn_li in electronic_issn_li_elements:\n",
    "                    electronic_issn_extract = re.search(r'ISSN:\\s+(\\d{4}-\\d{4}) \\(electronic\\)', electronic_issn_li.get_text(strip=True))\n",
    "                    if electronic_issn_extract:\n",
    "                        electronic_issn_extract = electronic_issn_extract.group(1)\n",
    "                        break\n",
    "                    else:\n",
    "                        electronic_issn_extract = \" \"\n",
    "\n",
    "            if electronic_issn_extract is None:\n",
    "                electronic_issn_li_list = soup.find('li', class_='c-list-group__item', string = re.compile(r'ISSN:\\s+\\d{4}-\\d{4} \\(electronic\\)'))\n",
    "                if electronic_issn_li_list:\n",
    "                    electronic_issn_extract = re.search(r'ISSN:\\s+(\\d{4}-\\d{4}) \\(electronic\\)', electronic_issn_li_list.get_text(strip=True))\n",
    "                    if electronic_issn_extract:\n",
    "                        electronic_issn_extract = electronic_issn_extract.group(1)\n",
    "                    else:\n",
    "                        electronic_issn_extract = \" \"\n",
    "                else:\n",
    "                    electronic_issn_extract = \" \"\n",
    "\n",
    "            #impact factor\n",
    "            impact_factor_extract = None\n",
    "            impact_factor_compare = r'^\\d\\.\\d \\- 2-year Impact Factor'\n",
    "\n",
    "            impact_factor_2y_dd = soup.find('dd', attrs={'data-test': 'impact-factor-value'})\n",
    "            if impact_factor_2y_dd:\n",
    "                impact_factor_text = impact_factor_2y_dd.get_text(strip=True)\n",
    "                impact_factor_extract = re.search(r'^([\\d.]+)', impact_factor_text)\n",
    "                if impact_factor_extract:\n",
    "                    impact_factor_extract = impact_factor_extract.group(1)\n",
    "                        \n",
    "            if impact_factor_extract is None:\n",
    "                impact_factor_span = soup.find('span', class_='impact-factor__value')\n",
    "                if impact_factor_span:\n",
    "                    impact_factor_extract = impact_factor_span.get_text(strip=True)\n",
    "\n",
    "            if impact_factor_extract is None:\n",
    "                impact_factor_2y_strong = soup.find('strong', string='2022 Citation Impact')\n",
    "                next_sibling = impact_factor_2y_strong.find_next_sibling('br') if impact_factor_2y_strong else None\n",
    "                impact_factor_extract = re.search(r'^\\d\\.\\d \\- \\d\\-\\w\\w\\w\\w \\w\\w\\w\\w\\w\\w \\w\\w\\w\\w\\w\\w$', next_sibling.next_sibling.strip()) if next_sibling and next_sibling.next_sibling else None\n",
    "                if impact_factor_extract:\n",
    "                    impact_factor = impact_factor_extract.group()\n",
    "                    if impact_factor and re.match(impact_factor_compare, impact_factor):\n",
    "                        impact_factor_extract = re.match(r'^\\d\\.\\d', impact_factor).group()\n",
    "                    else:\n",
    "                        impact_factor_extract = \" \"\n",
    "                else:\n",
    "                    impact_factor_extract = \" \"\n",
    "\n",
    "\n",
    "            STT+=1\n",
    "            springer_journals_data.append({\n",
    "                                        'STT': STT,\n",
    "                                        'Tên tạp chí': name_category.get_text().strip(),\n",
    "                                        'ISSN': print_issn_extract,\n",
    "                                        'eISSN': electronic_issn_extract,\n",
    "                                        'Impact Factor': impact_factor_extract})\n",
    "            \n",
    "        except requests.exceptions.RequestException as err:\n",
    "            print(\"Request error:\", err)\n",
    "            time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "springer_journals_data_book = pd.DataFrame(springer_journals_data, columns = ['STT', 'Tên tạp chí', 'ISSN', 'eISSN', 'Impact Factor'])\n",
    "springer_journals_data_book.to_csv('Crawling Springer Journal A-Z.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
